{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================HEADER_START=================================\n",
    "# %%\n",
    "#\n",
    "# COPYING, REPRODUCTION OR DISTRIBUTION SHOULD BE LIMITED AND ONLY TO\n",
    "# EMPLOYEES WITH A \"NEED TO KNOW\" TO DO THEIR JOB. ANY DISCLOSURE OF \n",
    "# THIS DOCUMENT TO THIRD PARTIES IS STRICTLY PROHIBITED.\n",
    "#\n",
    "# FILE: SUMMARIZE_TICKETS.IPYNB\n",
    "# DESCRIPTION: CREATE SUMMARY FOR ALL THE HISTORICAL TICKETS DOWNLOADED\n",
    "# FROM THE TEAMSUPPORT SYSTEM. COLUMNS USED FOR CREATING THE SUMMARY ARE\n",
    "# TICKET NAME & ACTION DESCRIPTION. USER COMMENTS ARE DULY UPDATED \n",
    "# TIME-WISE UNDER NAME ACTION DESCRIPTION. THIS DATE-WISE ACTION UPDATES\n",
    "# ARE FED INTO A LLM AND A SUMMARY IS CREATED FOR EACH TICKET.\n",
    "# \n",
    "# =========================HEADER_END==================================\n",
    "#\n",
    "# @AUTHOR YUVARAJ KUMAR NA\n",
    "# 14/JAN/2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALL ALL REQUIRED LIBRARIES\n",
    "#!pip install requests\n",
    "#!pip install xlsxwriter\n",
    "#!pip install tensorflow==2.12.0\n",
    "#!pip install transformers==4.30.2\n",
    "#!pip install sentence-transformers\n",
    "#!pip install tf-keras\n",
    "#!pip install huggingface_hub==0.14.1\n",
    "#!pip install --upgrade optree>=0.13.0\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuvaf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#IMPORT ALL GENERIC MODULES\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "#IMPORT ALL LIBRARIES FOR LLM COMMUNICATIONS\n",
    "import openai\n",
    "from openai.types.chat import ChatCompletion\n",
    "import requests\n",
    "import json\n",
    "import ast\n",
    "\n",
    "\n",
    "#IMPORT ALL LIBRARIES FOR EMBEDDINGS CREATION\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "#IMPORT ALL LIBRARIES FOR MONGODB OPERATIONS\n",
    "from pymongo import MongoClient, ASCENDING\n",
    "from pymongo.errors import BulkWriteError\n",
    "from bson import ObjectId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs>setx MSTRL_API_KEY \"ARjMS7D7bvpevisbN915oNCZnHgGTSPt\" \n",
      "\n",
      "SUCCESS: Specified value was saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GET API KEYS SET FOR MISTRAL LLM\n",
    "bat_file_path = r\"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\APIKEYS.bat\"\n",
    "\n",
    "#RUN THE BATCH FILE TO SET THE API KEYS\n",
    "try :\n",
    "    result = subprocess.run(bat_file_path, shell=True, check=True, text=True, capture_output=True)\n",
    "    print(result.stdout)\n",
    "    if result.stderr :\n",
    "        print(result.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred {e}\")\n",
    "\n",
    "#GET THE API KEY FROM THE ENVIRONMENT.\n",
    "try :\n",
    "    MSTRLAPI_KEY = os.getenv(\"MSTRL_API_KEY\")\n",
    "    if not MSTRLAPI_KEY:\n",
    "        raise ValueError(\"API keys not set\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred {e}\")\n",
    "\n",
    "#SET MODEL FOR EMBEDDING ENCODER\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant Response: Sure, I can help with that. When you provide the text entries, I will extract the most significant information from each entry to create a summary. This summary will then be used to generate embeddings, which can be utilized for similarity checks. Please go ahead and share the text entries one by one or in batches, and I will start processing them.\n"
     ]
    }
   ],
   "source": [
    "#KICK-START MISTRAL LLM COMMUNICATION FOR THE SUMMARIZATION STEPS REQUIRED\n",
    "endpoint_url = 'https://api.mistral.ai/v1/chat/completions'\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {MSTRLAPI_KEY}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    'model': 'mistral-large-latest',  # Replace with the appropriate model name if different\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'Hello Mistral...I will feed you nearly 1000 text entries of actions taken by users on Incident tickets. Pls create a summary of the text which will be used for similarity checks with their embeddings!'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(endpoint_url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print('Assistant Response:', data['choices'][0]['message']['content'])\n",
    "else:\n",
    "    print('Error:', response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'Ticket Number_1' created.\n",
      "Collection 'TSSP-Project' created with a unique index on 'Ticket Number'.\n"
     ]
    }
   ],
   "source": [
    "###STEP TO HAVE ALL THE FUNCTIONS REQUIRED FOR LLM ACTIVITIES, EMBEDDING GENERATION\n",
    "##TASKS, MONGO-DB DEFINITIONS ETC., TO BE CREATED\n",
    "##\n",
    "##\n",
    "\n",
    "#ALL MISTRAL LLM AND EMBEDDING FUNCTIONS ARE DEFINED BELOW\n",
    "# FUNCTION TO GET TICKET SUMMARY\n",
    "#PARAMETERS:\n",
    "# - ticket_story (str): The text of the ticket story to summarize.\n",
    "# - max_length (int): The maximum length of the summary.\n",
    "# - min_length (int): The minimum length of the summary.\n",
    "# - temperature (float): Controls the randomness of the output.\n",
    "# - num_beams (int): The number of beams for beam search.\n",
    "# - repetition_penalty (float): Penalty for repeating phrases.\n",
    "# - length_penalty (float): Penalty for longer summaries.\n",
    "def get_ticket_summary(ticket_story,max_length=4000, min_length=20, temperature=0.7, num_beams=4, repetition_penalty=2.0, length_penalty=1.0):\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {MSTRLAPI_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\n",
    "        'model': 'mistral-large-latest',\n",
    "        'messages': [{'role': 'user', 'content': ticket_story}]\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        return response.json().get('choices', [{'message': {'content': ''}}])[0]['message']['content']\n",
    "    except (requests.RequestException, ValueError, KeyError) as e:\n",
    "        print(f'Error processing ticket story: {e}')\n",
    "        return \"\"  # Return an empty string or a default value in case of error\n",
    "\n",
    "# FUNCTION TO GET TICKET EMBEDDING\n",
    "def get_ticket_embedding(ticket_summary):\n",
    "    if ticket_summary:\n",
    "        try:\n",
    "            # Preprocess the text (if needed, e.g., lowercasing, removing special characters)\n",
    "            preprocessed_summary = ticket_summary.lower().strip()\n",
    "            # Generate embedding\n",
    "            embedding = model.encode(preprocessed_summary)\n",
    "            # Replace out-of-range float values with a suitable default\n",
    "            embedding = np.nan_to_num(embedding, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            # Normalize the embedding to unit length\n",
    "            embedding_norm = embedding / np.linalg.norm(embedding)\n",
    "\n",
    "            return embedding_norm.tolist()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error encoding ticket summary: {e}')\n",
    "            return [0.0] * model.get_sentence_embedding_dimension()  # Return a default embedding of zeros\n",
    "    return None\n",
    "\n",
    "### MONGODB CONNECTION DETAILS\n",
    "mongo_uri = 'mongodb://localhost:27017/'  # Example for a local MongoDB instance\n",
    "database_name = 'TSS-Percentage'\n",
    "collection_name = 'TSSP-Project'\n",
    "\n",
    "# CONNECT TO MONGODB, DATABASE & CREATE THE COLLECTION WITH UNIQUE INDEX ON \"TICKET NUMBER\"\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Create a unique index on the 'Ticket Number' field\n",
    "# This ensures that each 'Ticket Number' is unique in the collection\n",
    "# Define the index specification\n",
    "index_name = 'Ticket Number_1'  # MongoDB automatically appends '_1' for single-field indexes\n",
    "index_info = collection.index_information()\n",
    "\n",
    "# CHECK IF THE INDEX ALREADY EXISTS\n",
    "if index_name not in index_info:\n",
    "    # Create the unique index\n",
    "    collection.create_index('Ticket Number', unique=True, name=index_name)\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "print(f\"Collection '{collection_name}' created with a unique index on 'Ticket Number'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "['Group Name', 'Ticket Name', 'Ticket Number', 'Action Creator Name', 'Action Description', 'Date Action Created', 'Action Type']\n",
      "\n",
      "Basic statistics\n",
      "Total Tickets in Excel: 838\n",
      "Ticket Number range in Excel: 3017645 ~ 3708324\n",
      "\n",
      "Data Types:\n",
      "Group Name             object\n",
      "Ticket Name            object\n",
      "Ticket Number           int64\n",
      "Action Creator Name    object\n",
      "Action Description     object\n",
      "Date Action Created    object\n",
      "Action Type            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "###PRINT MIN STATISTICS OF THE INPUT FILE DOWNLOADED FROM THE TICKET SITE\n",
    "##\n",
    "\n",
    "file_path=\"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\InvestOne_1Y_Report.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nBasic statistics\")\n",
    "tkt_count = df[\"Ticket Number\"].nunique()\n",
    "min_value = df[\"Ticket Number\"].min()\n",
    "max_value = df[\"Ticket Number\"].max()\n",
    "print(\"Total Tickets in Excel:\", tkt_count)\n",
    "print(\"Ticket Number range in Excel:\", min_value , \"~\" , max_value)\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ticket Name', 'Ticket Number', 'Action Description', 'Date Action Created', 'Action Type']\n"
     ]
    }
   ],
   "source": [
    "# COLUMNS UNWANTED FOR SUMMARIZATION ARE DROPPED\n",
    "cols_to_drop=['Group Name','Action Creator Name']\n",
    "df=df.drop(columns=cols_to_drop,axis=1)\n",
    "\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before filtering non-numeric 'Ticket Number': 838\n",
      "Number of rows after filtering non-numeric 'Ticket Number': 838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvaf\\AppData\\Local\\Temp\\ipykernel_3988\\2005457089.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ticket_story = filtered_df.groupby('Ticket Number').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticket Number                                       Ticket Story\n",
      "0        3017645  Warning MQ requests (FM82) in TXC SISTCL10 may...\n",
      "1        3018629  AMPBLUSAGEF abort\\nJob aborted with following:...\n",
      "The CSV file has 838 records.\n"
     ]
    }
   ],
   "source": [
    "####STEP TO CREATE \"TICKET STORY\" BY CONCATENATING \"ACTION DESCRIPTION\" AND \"COMMENT\" ITEMS OF THE TICKET.\n",
    "##THIS CONCATENATION RECORDS ALL THE ACTIONS THAT ARE PERFORMED FOR THE TICKET RESOLUTION. THIS TEXT WILL\n",
    "##BE DESCRIPTIVE DETAIL IN PLAIN ENGLISH, OR FUNCTIONAL COMMANDS EXECUTED IN TECHNICAL JARGON, OR MIX OF\n",
    "##DIFFERENT SUCH ACTIONS PERFORMED BY THE ENGINEERS. THIS WILL BE FED INTO THE LLM TO GENERATE \"TICKET SUMMMARY\"\n",
    "##IN PLAIN ENGLISH.\n",
    "##point to note :  ONLY STRING TEXT ARE TAKEN FOR THIS USE-CASE. IMAGES, SCREENSHOTS ETC., ARE DISCARDED\n",
    "##FOR EASE OF THE USE-CASE\n",
    "\n",
    "# COLUMNS WANTED FOR SUMMARIZATION PER TICKET ARE GROUPED \"TICKET NAME\",\"\" ACTION DESCRIPTION\" SORTED ON \"DATE ACTION CREATED\" ARE UPDATED INTO A NEW FILE WITH NEW  COLUMN NAMED \"TICKET STORY\" TO CREATE \"TICKET SUMMARY\"\n",
    "filtered_df = df[df['Action Type'].isin(['Description','Comment'])]\n",
    "\n",
    "# CONVERT 'DATE ACTION CREATED' TO DATETIME IF IT'S NOT ALREADY\n",
    "#FILTERED_DF['DATE ACTION CREATED'] = PD.TO_DATETIME(FILTERED_DF['DATE ACTION CREATED'], FORMAT='%M/%D/%Y %I:%M %P')\n",
    "\n",
    "# SORT VALUES BY 'DATE ACTION CREATED'\n",
    "filtered_df = filtered_df.sort_values(by='Date Action Created')\n",
    "\n",
    "# GROUP BY 'TICKET NUMBER' AND CONCATENATE 'ACTION DESCRIPTION'\n",
    "ticket_story = filtered_df.groupby('Ticket Number').apply(\n",
    "    lambda group: (\n",
    "        f\"{group['Ticket Name'].iloc[0]}\\n\" +  # Start with the unique 'Ticket Name'\n",
    "        \"\\n\".join(map(str, group['Action Description']))  # Join 'Action Description' with new lines\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "# RENAME THE COLUMNS FOR CLARITY\n",
    "ticket_story.columns = ['Ticket Number', 'Ticket Story']\n",
    "\n",
    "# REMOVE DUPLICATE ENTRIES BASED ON 'TICKET NUMBER'\n",
    "ticket_story = ticket_story.drop_duplicates(subset='Ticket Number')\n",
    "\n",
    "# PRINT THE NUMBER OF ROWS BEFORE FILTERING\n",
    "print(f\"Number of rows before filtering non-numeric 'Ticket Number': {ticket_story.shape[0]}\")\n",
    "\n",
    "# DROP ROWS WHERE 'TICKET NUMBER' IS NOT NUMERIC\n",
    "ticket_story['Ticket Number'] = pd.to_numeric(ticket_story['Ticket Number'], errors='coerce')\n",
    "ticket_story = ticket_story.dropna(subset=['Ticket Number'])\n",
    "\n",
    "# PRINT THE NUMBER OF ROWS AFTER FILTERING\n",
    "print(f\"Number of rows after filtering non-numeric 'Ticket Number': {ticket_story.shape[0]}\")\n",
    "\n",
    "# WRITE TO CSV FILE WITH CLEAR COLUMN NAMES\n",
    "output_file_path = r\"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_Story.csv\"\n",
    "ticket_story.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(ticket_story.head(2))\n",
    "\n",
    "# PRINT THE RECORD COUNT\n",
    "print(f\"The CSV file has {(pd.read_csv(output_file_path)).shape[0]} records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 at 2025-03-14 11:53:36...\n",
      "Data has been written to C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_output_sample_5.csv\n"
     ]
    }
   ],
   "source": [
    "#################     DANGER - TIME CONSUMING STEP AS LLM CONNECTION IS MADE ################\n",
    "#                     DANGER - TIME CONSUMING STEP AS LLM CONNECTION IS MADE\n",
    "#                     DANGER - TIME CONSUMING STEP AS LLM CONNECTION IS MADE\n",
    "\n",
    "#####THIS IS A TIME CONSUMING STEP WHERE FOR ALL TICKETS, LLM CONNECTION IS MADE FOR CREATING\n",
    "##SUMMARY, GENERATING EMBEDDINGS ETC., WE MAY RUN INTO LONG RUNS/DELAYS/ERRORS WITH NEW OR\n",
    "##UNPROCESSED DATA. TIMLINES OF THIS STEP ARE GIVEN BELOW.\n",
    "## 802  TICKETS (1 YR TICKETs) - 5h 35m\n",
    "## 2567 TICKETS (3 YR TICKETs) - 17h 58m (High Chances of getting into 429 - RateLimitError with free version)\n",
    "## 5744 TICKETS (5 YR TICKETs) - xh ym (got into 429 - RateLimitError due to free version of Mistral LLM)\n",
    "\n",
    "# CREATE SUMMARY AND EMBEDDING FROM \"TICKET STORY\" FOR EACH TICKET\n",
    "# USING LLMS AND VECTOR EMBEDDING TRANSFORMER MODELS\n",
    "#############REAL DATASET#################\n",
    "#file_path=\"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_Story.csv\" \n",
    "#output_file_path = \"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_output.csv\"   \n",
    "\n",
    "#############DEMO DATASET#################\n",
    "file_path=\"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_Story_sample_5.csv\"    \n",
    "output_file_path = \"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_output_sample_5.csv\"\n",
    "\n",
    "# PROCESS THE CSV FILE IN BATCHES\n",
    "processed_data = []     # Initialize an empty list to store processed data\n",
    "iteration = 0           # Initialize a counter for iterations\n",
    "batch_size = 25         # Define the batch size\n",
    "\n",
    "# INITIALIZE AN EMPTY LIST TO STORE PROCESSED DATA\n",
    "processed_data = []\n",
    "\n",
    "# INITIALIZE A COUNTER FOR ITERATIONS\n",
    "iteration = 0\n",
    "\n",
    "# READ THE CSV FILE IN CHUNKS\n",
    "for chunk in pd.read_csv(file_path, chunksize=batch_size):\n",
    "    # Increment the iteration counter\n",
    "    iteration += 1\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'Processing batch {iteration} at {current_time}...')\n",
    "\n",
    "    # Process each chunk\n",
    "    chunk['Ticket Summary'] = chunk['Ticket Story'].apply(get_ticket_summary)\n",
    "    chunk['Ticket Embedding'] = chunk['Ticket Summary'].apply(get_ticket_embedding)\n",
    "\n",
    "    # Append the processed chunk to the list\n",
    "    processed_data.append(chunk)\n",
    "\n",
    "# CONCATENATE ALL PROCESSED CHUNKS INTO A SINGLE DATAFRAME\n",
    "final_data = pd.concat(processed_data, ignore_index=True)\n",
    "\n",
    "# WRITE THE DATA TO A NEW CSV FILE\n",
    "final_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Data has been written to', output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file has 838 records.\n",
      "838 records inserted into MongoDB.\n"
     ]
    }
   ],
   "source": [
    "####STEP TO LOAD THE CSV FILE {'TICKET NUMBER','TICKET STORY','TICKET SUMMARY','TICKET EMBEDDING'}\n",
    "##INTO MONGODB WHICH GOT CREATED IN ABOVE STEP.\n",
    "##\n",
    "\n",
    "#output_file_path=\"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_output.csv\"   #REAL DATASET\n",
    "output_file_path=\"C:\\Yuvpersonal\\AIML\\M.Tech BITS-Pilani\\Sem 4\\Project Docs\\Ticket_output_sample_5.csv\"  #DEMO DATASET\n",
    "\n",
    "\n",
    "print(f\"The CSV file has {(pd.read_csv(output_file_path)).shape[0]} records.\")\n",
    "\n",
    "# READ THE CSV FILE INTO A DATAFRAME\n",
    "df = pd.read_csv(output_file_path)\n",
    "\n",
    "# CONVERT THE DATAFRAME TO A LIST OF DICTIONARIES\n",
    "records = df.to_dict(orient='records')\n",
    "\n",
    "# INSERT THE RECORDS INTO THE MONGODB COLLECTION\n",
    "try:\n",
    "    # Insert the records into the MongoDB collection, ignoring duplicates\n",
    "    result = collection.insert_many(records, ordered=False)\n",
    "    print(f'{len(result.inserted_ids)} records inserted into MongoDB.')\n",
    "except BulkWriteError as bwe:\n",
    "    # Handle duplicate key errors and other bulk write errors\n",
    "    print(f'{len(bwe.details[\"writeErrors\"])} records failed to insert due to duplicate key errors.')\n",
    "\n",
    "# CLOSE THE MONGODB CONNECTION\n",
    "#client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=838)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=838)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='euclidean', n_neighbors=838)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####PREPARATORY STEP TO PICK ALL EMBEDDINGS FROM TSSP-PROJECT MONGODB COLLECTION WHICH GOT  \n",
    "# INSERTED IN EARLIER STEPS AND GET IT MAPPED ON 384 DIMENSIONAL EUCLIDEAN SPACE TO FIND OUT THE \n",
    "##NEAREST KNN ELEMENTS WHICH CORRESPONDS TO SIMILAR TICKETS\n",
    "##\n",
    "\n",
    "# FETCH ALL EMBEDDINGS AND THEIR CORRESPONDING IDS AND TICKET NUMBERS FROM MONGODB\n",
    "documents = list(collection.find({}, {'_id': 1, 'Ticket Embedding': 1, 'Ticket Number': 1}))\n",
    "\n",
    "# ENSURE ALL EMBEDDINGS ARE NUMERIC, NON-EMPTY, AND HAVE THE SAME LENGTH\n",
    "valid_embeddings = []\n",
    "valid_ids = []\n",
    "valid_ticket_numbers = []\n",
    "dimension = None\n",
    "\n",
    "for doc in documents:\n",
    "    embedding = doc.get('Ticket Embedding', [])\n",
    "    doc_id = str(doc['_id'])\n",
    "    ticket_number = doc.get('Ticket Number', '')\n",
    "\n",
    "    if not embedding:\n",
    "        print(f\"Skipping empty embedding for document ID: {doc_id}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Convert string representation of embedding to a list of floats\n",
    "        embedding_list = ast.literal_eval(embedding)\n",
    "        embedding_np = np.array(embedding_list, dtype='float32')\n",
    "\n",
    "        if embedding_np.ndim != 1:\n",
    "            print(f\"Skipping malformed embedding for document ID: {doc_id}\")\n",
    "            continue\n",
    "\n",
    "        if dimension is None:\n",
    "            dimension = embedding_np.shape[0]\n",
    "        elif embedding_np.shape[0] != dimension:\n",
    "            print(f\"Skipping embedding with incorrect dimension for document ID: {doc_id}\")\n",
    "            continue\n",
    "\n",
    "        valid_embeddings.append(embedding_np)\n",
    "        valid_ids.append(doc_id)\n",
    "        valid_ticket_numbers.append(ticket_number)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(f\"Skipping non-numeric embedding for document ID: {doc_id}\")\n",
    "\n",
    "# CHECK IF THERE ARE ANY VALID EMBEDDINGS\n",
    "if not valid_embeddings:\n",
    "    raise ValueError(\"No valid embeddings found.\")\n",
    "\n",
    "# CONVERT VALID EMBEDDINGS TO A NUMPY ARRAY\n",
    "embeddings_np = np.vstack(valid_embeddings)\n",
    "\n",
    "# INITIALIZE A NEARESTNEIGHBORS MODEL\n",
    "n_neighbors = len(valid_embeddings)  # Retrieve all to filter later\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')\n",
    "knn.fit(embeddings_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Ticket # is: '3692365'\n",
      "Similar Tickets found are:\n",
      "3133798 - 100.00%\n"
     ]
    }
   ],
   "source": [
    "####RUN STEP TO PICK 5NN NEAREST NEIGHBOURS IN THE 384 DIMENSIONAL EUCLIDEAN SPACE\n",
    "##AND DISPLAY THE TICKET NUMBERS AND THEIR SIMILARITY DISTANCES\n",
    "##\n",
    "##TEST TYPE 1 : FINDING Knn - K nearest neigbours\n",
    "\n",
    "# PROMPT THE USER FOR A TICKET NUMBER AND CONVERT IT TO AN INTEGER\n",
    "ticket_number_input = input(\"Enter the Ticket Number: \")\n",
    "try:\n",
    "    ticket_number = int(ticket_number_input)\n",
    "except ValueError:\n",
    "    print(\"Invalid Ticket Number. Please enter a valid integer.\")\n",
    "    exit()\n",
    "\n",
    "# FETCH THE EMBEDDING FOR THE GIVEN TICKET NUMBER\n",
    "ticket_document = collection.find_one({'Ticket Number': ticket_number})\n",
    "\n",
    "if ticket_document is None:\n",
    "    print(f\"No embedding found for Ticket Number: {ticket_number}\")\n",
    "else:\n",
    "    try:\n",
    "        # Convert the embedding to a numpy array\n",
    "        query_vector = np.array(ast.literal_eval(ticket_document['Ticket Embedding']), dtype='float32')\n",
    "\n",
    "        # Perform the search\n",
    "        distances, indices = knn.kneighbors([query_vector])\n",
    "\n",
    "        # Retrieve the corresponding ticket numbers and distances\n",
    "        similar_ticket_numbers = [valid_ticket_numbers[i] for i in indices[0]]\n",
    "        similar_distances = distances[0]\n",
    "\n",
    "        # Exclude the given ticket from the results\n",
    "        similar_ticket_numbers = [tn for tn, dist in zip(similar_ticket_numbers, similar_distances) if tn != ticket_number]\n",
    "        similar_distances = [dist for tn, dist in zip(similar_ticket_numbers, similar_distances) if tn != ticket_number]\n",
    "\n",
    "        # Calculate similarity percentages\n",
    "        similar_tickets_with_similarity = [\n",
    "            (tn, max(0, (1 - dist) * 100)) for tn, dist in zip(similar_ticket_numbers, similar_distances)\n",
    "        ]\n",
    "\n",
    "        # Filter tickets with similarity greater than or equal to 40%\n",
    "        similar_tickets_with_similarity = [\n",
    "            (tn, similarity) for tn, similarity in similar_tickets_with_similarity if similarity >= 40\n",
    "        ]\n",
    "\n",
    "        # Sort by similarity and limit to 5 results\n",
    "        similar_tickets_with_similarity = sorted(similar_tickets_with_similarity, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Given Ticket # is: '{ticket_number}'\")\n",
    "        print(\"Similar Tickets found are:\")\n",
    "        if similar_tickets_with_similarity:\n",
    "            for tn, similarity in similar_tickets_with_similarity:\n",
    "                print(f\"{tn} - {similarity:.2f}%\")\n",
    "        else:\n",
    "            print(\"No similar tickets found with 40% or higher similarity.\")\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(f\"Invalid embedding format for Ticket Number: {ticket_number}\")\n",
    "\n",
    "# CLOSE THE MONGODB CONNECTION\n",
    "#client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####DEFINE STEP TO GET A NEW TICKET NUMBER AND FIND CLOSEST Knn\n",
    "##DISPLAY THE SIMILAR TICKET NUMBERS AND THEIR DISTANCES\n",
    "##\n",
    "##TEST TYPE 2 : FOR A NEW TICKET FIND Knn\n",
    "def find_similar_tickets(ticket_number, ticket_description, knn, valid_ticket_numbers, top_n=5):\n",
    "    # Generate embedding for the ticket description\n",
    "    query_vector = get_ticket_embedding(ticket_description)\n",
    "\n",
    "    # Convert the list to a NumPy array and reshape it\n",
    "    query_vector = np.array(query_vector).reshape(1, -1)\n",
    "\n",
    "    # Perform the k-NN search\n",
    "    distances, indices = knn.kneighbors(query_vector)\n",
    "\n",
    "    # Retrieve the corresponding ticket numbers and distances\n",
    "    similar_ticket_numbers = [valid_ticket_numbers[i] for i in indices[0]]\n",
    "    similar_distances = distances[0]\n",
    "\n",
    "    # Exclude the given ticket from the results\n",
    "    similar_ticket_numbers = [tn for tn, dist in zip(similar_ticket_numbers, similar_distances) if tn != ticket_number]\n",
    "    similar_distances = [dist for tn, dist in zip(similar_ticket_numbers, similar_distances) if tn != ticket_number]\n",
    "\n",
    "    # Calculate similarity percentages\n",
    "    similar_tickets_with_similarity = [\n",
    "        (tn, max(0, (1 - dist) * 100)) for tn, dist in zip(similar_ticket_numbers, similar_distances)\n",
    "    ]\n",
    "\n",
    "    # Filter tickets with similarity greater than or equal to 40%\n",
    "    similar_tickets_with_similarity = [\n",
    "        (tn, similarity) for tn, similarity in similar_tickets_with_similarity if similarity >= 1\n",
    "    ]\n",
    "\n",
    "    # Sort by similarity and limit to top_n results\n",
    "    similar_tickets_with_similarity = sorted(similar_tickets_with_similarity, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    return similar_tickets_with_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Ticket # is: '3987654'\n",
      "Similar Tickets found are:\n",
      "3614378 - 5.97%\n",
      "3513922 - 5.89%\n",
      "3628470 - 4.23%\n",
      "3163198 - 3.38%\n",
      "3680806 - 3.14%\n"
     ]
    }
   ],
   "source": [
    "####RUN STEP TO GET A NEW TICKET NUMBER AND FIND CLOSEST Knn\n",
    "##DISPLAY THE SIMILAR TICKET NUMBERS AND THEIR DISTANCES\n",
    "##\n",
    "##TEST TYPE 2 : FOR A NEW TICKET FIND Knn\n",
    "# Prompt the user for a ticket number and description\n",
    "ticket_number_input = input(\"Enter the Ticket Number: \")\n",
    "ticket_description_input = input(\"Enter the Ticket Description: \")\n",
    "\n",
    "try:\n",
    "    ticket_number = int(ticket_number_input)\n",
    "except ValueError:\n",
    "    print(\"Invalid Ticket Number. Please enter a valid integer.\")\n",
    "    exit()\n",
    "\n",
    "# Find similar tickets\n",
    "similar_tickets = find_similar_tickets(ticket_number, ticket_description_input, knn, valid_ticket_numbers)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Given Ticket # is: '{ticket_number}'\")\n",
    "print(\"Similar Tickets found are:\")\n",
    "if similar_tickets:\n",
    "    for tn, similarity in similar_tickets:\n",
    "        print(f\"{tn} - {similarity:.2f}%\")\n",
    "else:\n",
    "    print(\"No similar tickets found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
